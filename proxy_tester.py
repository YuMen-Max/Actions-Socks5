import os
import time
import re
import requests
from requests.exceptions import ProxyError, ConnectTimeout, ReadTimeout, ConnectionError
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
from tqdm import tqdm

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def extract_proxy(line):
    pattern = r'(?:socks5://)?([a-zA-Z0-9_\-]+:[a-zA-Z0-9_\-]+@\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+)(?:#.*)?'
    match = re.search(pattern, line)
    return match.group(1) if match else None

def test_proxy(proxy):
    proxies = {'http': f'socks5://{proxy}', 'https': f'socks5://{proxy}'}
    try:
        start = time.time()
        response = requests.get('http://www.gstatic.com/generate_204', proxies=proxies, timeout=2)
        latency = int((time.time() - start) * 1000)
        if response.status_code == 204:
            logging.info(f"âœ… æœ‰æ•ˆä»£ç†: {proxy} | å»¶è¿Ÿ: {latency}ms")
            return proxy
    except (ProxyError, ConnectTimeout, ReadTimeout, ConnectionError):
        pass
    except Exception as e:
        logging.warning(f"âš ï¸ æµ‹è¯•å¼‚å¸¸: {proxy} | é”™è¯¯: {str(e)}")
    logging.info(f"âŒ æ— æ•ˆä»£ç†: {proxy}")
    return None

def read_input_proxies(input_file):
    if not os.path.exists(input_file):
        logging.warning(f"âš ï¸ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return []
    try:
        with open(input_file, 'r') as f:
            proxies = [extract_proxy(line.strip()) for line in f if line.strip()]
            proxies = [p for p in proxies if p]
            logging.info(f"ğŸ“– ä» {input_file} æå– {len(proxies)} ä¸ªä»£ç†")
            return proxies
    except Exception as e:
        logging.error(f"âš ï¸ è¯»å–æ–‡ä»¶ {input_file} å¤±è´¥: {str(e)}")
        return []

def save_valid_proxies(valid_proxies, output_file):
    try:
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, 'w') as f:
            f.write('\n'.join(valid_proxies))
        logging.info(f"ğŸ“ ä¿å­˜ {len(valid_proxies)} ä¸ªæœ‰æ•ˆä»£ç†åˆ° {output_file}")
        return True
    except Exception as e:
        logging.error(f"âš ï¸ ä¿å­˜æ–‡ä»¶ {output_file} å¤±è´¥: {str(e)}")
        return False

def main():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    input_file = os.path.join(script_dir, "china.txt")
    output_file = os.path.join(script_dir, "telecom.txt")
    logging.info(f"ğŸ“‚ è„šæœ¬ç›®å½•: {script_dir}")
    logging.info(f"ğŸ“ è¾“å…¥æ–‡ä»¶è·¯å¾„: {input_file}")
    logging.info(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶è·¯å¾„: {output_file}")

    if not os.path.exists(input_file):
        logging.error(f"âŒ è¾“å…¥æ–‡ä»¶ {input_file} ä¸å­˜åœ¨")
        return 0

    all_proxies = read_input_proxies(input_file)
    if not all_proxies:
        logging.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ä»£ç†ï¼Œè·³è¿‡æµ‹è¯•")
        return 0

    valid_proxies = []
    with ThreadPoolExecutor(max_workers=10) as executor:
        future_to_proxy = {executor.submit(test_proxy, proxy): proxy for proxy in all_proxies}
        for future in tqdm(as_completed(future_to_proxy), total=len(all_proxies), desc="æµ‹è¯•ä»£ç†"):
            result = future.result()
            if result:
                valid_proxies.append(result)

    if valid_proxies:
        save_valid_proxies(valid_proxies, output_file)
    else:
        with open(output_file, 'w') as f:
            f.write('')
        logging.info("ğŸ“ æ¸…ç©ºè¾“å‡ºæ–‡ä»¶ï¼ˆæ— æœ‰æ•ˆä»£ç†ï¼‰")

    if os.path.exists(output_file):
        with open(output_file, 'r') as f:
            content = f.read()
            logging.info(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶å†…å®¹ (å‰100å­—ç¬¦): {content[:100]}{'...' if len(content) > 100 else ''}")
            logging.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")

    logging.info(f"âœ… æµ‹è¯•å®Œæˆ - æœ‰æ•ˆä»£ç†: {len(valid_proxies)}/{len(all_proxies)}")
    return len(valid_proxies)

if __name__ == "__main__":
    main()